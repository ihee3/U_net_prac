{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##U-net 네트워크 구현하기 \n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "data_dir = './EMdataset'\n",
    "ckpt_dir = './checkpoint'\n",
    "log_dir = './log'\n",
    "result_dir = './results'\n",
    "\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    " \n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')##트레이닝 하이퍼 파라메터 설정하기\n",
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epoch = 100\n",
    "\n",
    "#트레이닝 정보를 저장할 디렉토리\n",
    "\n",
    "##네트워크 구축하기\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        \n",
    "        def CBR2d(in_channel, out_channel, kernel_size=3, stride=1, padding=1, bias=True):\n",
    "            layers = []\n",
    "            \n",
    "            layers += [nn.Conv2d(in_channels=in_channel, out_channels=out_channel,\n",
    "                                 kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                                bias=bias)]\n",
    "            \n",
    "            layers += [nn.BatchNorm2d(num_features = out_channel)]\n",
    "            \n",
    "            layers += [nn.ReLU()]\n",
    "            \n",
    "            cbr = nn.Sequential(*layers)\n",
    "            return cbr\n",
    "        \n",
    "        #Encoder part\n",
    "        self.enc1_1 = CBR2d(in_channel=1, out_channel=64) \n",
    "        self.enc1_2 = CBR2d(in_channel=64, out_channel=64)\n",
    "        \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size =2) # image shape 1/2 #\n",
    "        \n",
    "        self.enc2_1 = CBR2d(in_channel=64, out_channel=128)\n",
    "        self.enc2_2 = CBR2d(in_channel=128, out_channel=128)\n",
    "        \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size =2) # image shape 1/2 #\n",
    "        \n",
    "        self.enc3_1 = CBR2d(in_channel=128, out_channel=256)\n",
    "        self.enc3_2 = CBR2d(in_channel=256, out_channel=256)\n",
    "        \n",
    "        self.pool3 = nn.MaxPool2d(kernel_size =2) # image shape 1/2 #\n",
    "        \n",
    "        self.enc4_1 = CBR2d(in_channel=256, out_channel=512)\n",
    "        self.enc4_2 = CBR2d(in_channel=512, out_channel=512)\n",
    "        \n",
    "        self.pool4 = nn.MaxPool2d(kernel_size =2) # image shape 1/2 #\n",
    "        \n",
    "        self.enc5 = CBR2d(in_channel=512, out_channel=1024)\n",
    "        \n",
    "        #Decoder part\n",
    "        self.dec5 = CBR2d(in_channel=1024, out_channel=512)\n",
    "        \n",
    "        self.unpool4 = nn.ConvTranspose2d(in_channels=512, out_channels=512,\n",
    "                                         kernel_size=2, stride=2, padding=0, bias=True) # image shape *2 #\n",
    "        \n",
    "        self.dec4_2 = CBR2d(in_channel=2*512, out_channel = 512)\n",
    "        self.dec4_1 = CBR2d(in_channel=512, out_channel = 256)\n",
    "        \n",
    "        self.unpool3 = nn.ConvTranspose2d(in_channels=256, out_channels=256,\n",
    "                                         kernel_size=2, stride=2, padding=0, bias=True) # image shape *2 #\n",
    "        \n",
    "        self.dec3_2 = CBR2d(in_channel=2*256, out_channel = 256)\n",
    "        self.dec3_1 = CBR2d(in_channel=256, out_channel = 128)\n",
    "        \n",
    "        self.unpool2 = nn.ConvTranspose2d(in_channels=128, out_channels=128,\n",
    "                                         kernel_size=2, stride=2, padding=0, bias=True) # image shape *2 #\n",
    "        \n",
    "        self.dec2_2 = CBR2d(in_channel=2*128, out_channel = 128)\n",
    "        self.dec2_1 = CBR2d(in_channel=128, out_channel = 64)\n",
    "        \n",
    "        self.unpool1 = nn.ConvTranspose2d(in_channels=64, out_channels=64,\n",
    "                                         kernel_size=2, stride=2, padding=0, bias=True) # image shape *2 #\n",
    "        \n",
    "        self.dec1_2 = CBR2d(in_channel=2*64, out_channel = 64)\n",
    "        self.dec1_1 = CBR2d(in_channel=64, out_channel = 64)\n",
    "        \n",
    "        #n개의 클래스를 갖는 출력을 만들어주기 위해 1*1 conv\n",
    "        self.fc = nn.Conv2d(in_channels=64, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            enc1_1 = self.enc1_1(x)\n",
    "            enc1_2 = self.enc1_2(enc1_1)\n",
    "            pool1 = self.pool1(enc1_2)\n",
    "            \n",
    "            enc2_1 = self.enc2_1(pool1)\n",
    "            enc2_2 = self.enc2_2(enc2_1)\n",
    "            pool2 = self.pool2(enc2_2)\n",
    "            \n",
    "            enc3_1 = self.enc3_1(pool2)\n",
    "            enc3_2 = self.enc3_2(enc3_1)\n",
    "            pool3 = self.pool3(enc3_2)\n",
    "            \n",
    "            enc4_1 = self.enc4_1(pool3)\n",
    "            enc4_2 = self.enc4_2(enc4_1)\n",
    "            pool4 = self.pool4(enc4_2)\n",
    "            \n",
    "            enc5 = self.enc5(pool4)\n",
    "            \n",
    "            dec5 = self.dec5(enc5)\n",
    "            \n",
    "            unpool4 = self.unpool3(dec5)\n",
    "            cat4 = torch.cat((unpool4, enc4_2), dim=1)\n",
    "            dec4_2 = self.dec4_2(cat4)\n",
    "            dec4_1 = self.dec4_1(dec4_2)\n",
    "            \n",
    "            unpool3 = self.unpool3(dec4_1)\n",
    "            cat3 = torch.cat((unpool3, enc3_2), dim=1)\n",
    "            dec3_2 = self.dec3_2(cat3)\n",
    "            dec3_1 = self.dec3_1(dec3_2)\n",
    "            \n",
    "            unpool2 = self.unpool2(dec3_1)\n",
    "            cat2 = torch.cat((unpool2, enc2_2), dim=1)\n",
    "            dec2_2 = self.dec4_2(cat2)\n",
    "            dec2_1 = self.dec4_1(dec2_2)\n",
    "            \n",
    "            unpool1 = self.unpool1(dec2_1)\n",
    "            cat1 = torch.cat((unpool1, enc1_2), dim=1)\n",
    "            dec1_2 = self.dec4_2(cat1)\n",
    "            dec1_1 = self.dec4_1(dec1_2)\n",
    "            \n",
    "            x = self.fc(dec1_1)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "#데이터 로더 구현 \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        lst_data = os.listdir(self.data_dir)\n",
    "\n",
    "        lst_label = [f for f in lst_data if f.startswith('label')]\n",
    "        lst_input = [f for f in lst_data if f.startswith('input')]\n",
    "\n",
    "        lst_label.sort()\n",
    "        lst_input.sort()\n",
    "\n",
    "        self.lst_label = lst_label\n",
    "        self.lst_input = lst_input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lst_label)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        label = np.load(os.path.join(self.data_dir, self.lst_label[index]))\n",
    "        input = np.load(os.path.join(self.data_dir, self.lst_input[index]))\n",
    "\n",
    "        label = label/255.0\n",
    "        input = input/255.0\n",
    "\n",
    "        # making channel dimension \n",
    "        if label.ndim == 2:\n",
    "            label = label[:, : , np.newaxis]\n",
    "        if input.ndim == 2:\n",
    "            input = input[:, :, np.newaxis]\n",
    "\n",
    "        data = {'input': input, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "dataset_train = Dataset(data_dir=os.path.join(data_dir, 'train'))\n",
    "\n",
    "##Transform implemation\n",
    "class ToTensor(object):\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        label = label.transpose((2, 0, 1)).astype(np.float32)\n",
    "        input = input.transpose((2, 0, 1)).astype(np.float32)\n",
    "\n",
    "        data = {'label': torch.from_numpy(label), 'input': torch.from_numpy(input)}\n",
    "\n",
    "        return data\n",
    "\n",
    "class Normalization(object):\n",
    "    def __init__(self, mean = 0.5, std = 0.5):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        input = (input - self.mean) / self.std\n",
    "        #label은 0 or 1로 되어있지 때문에 해주지 않아\n",
    "\n",
    "        data = {'label': label, 'input': input}\n",
    "\n",
    "        return data\n",
    "\n",
    "class RandomFlip(object):\n",
    "    def __call__(self, data):\n",
    "        label, input = data['label'], data['input']\n",
    "\n",
    "        if np.random.rand() > 0.5:\n",
    "            label = np.fliplr(label)\n",
    "            input = np.fliplr(input)\n",
    "\n",
    "        if np.random.rand() < 0.5:\n",
    "            label = np.flipud(label)\n",
    "            input = np.flipud(input)\n",
    "\n",
    "        data = {'label': label, 'input':input}\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "transform = transforms.Compose([Normalization(mean=0.5, std= 0.5), \n",
    "ToTensor()])\n",
    "\n",
    "#training\n",
    "    #data load\n",
    "transform = transforms.Compose([Normalization(mean=0.5, std=0.5), RandomFlip(), ToTensor()])\n",
    "\n",
    "dataset_test = Dataset(data_dir=os.path.join(data_dir, 'test'), transform=transform)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "\n",
    "    ##network\n",
    "net = Unet().to(device)\n",
    "\n",
    "    ##define loss function\n",
    "fn_loss = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "    ## set optimizer\n",
    "optim = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    #부수적인 variable 설정하기\n",
    "num_data_test = len(dataset_test)\n",
    "\n",
    "num_batch_test = np.ceil(num_data_test / batch_size)\n",
    "\n",
    "#부수적인 functions 설정하기\n",
    "fn_tonumpy = lambda x: x.to('cpu').detach().numpy().transpose(0, 2, 3, 1)\n",
    "fn_denorm =  lambda x, mean, std: (x*sed)+mean\n",
    "fn_class = lambda x: 1.0 * (x > 0.5)\n",
    "\n",
    "\n",
    "#네트워크 저장\n",
    "def save(ckpt_dir, net, optim, epoch):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "\n",
    "    torch.save({'net': net.state_dict(), 'optim': optim.state_dict()}, \"./s%/model_epoch%d.pth\" % (ckpt_dir, epoch))\n",
    "\n",
    "#네트워크 불러오기\n",
    "def load(ckpt_dir, net, optim):\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        epoch = 0\n",
    "        return net, optim, epoch\n",
    "\n",
    "    ckpt_lst = os.listdir(ckpt_dir)\n",
    "    ckpt_lst.sort(key = lambda f: int(\"\".join(filter(str.isdigit, f))))\n",
    "\n",
    "    dict_model = torch.load('./%s/%s' % (ckpt_dir, ckpt_lst[-1]))\n",
    "\n",
    "    net.load_state_dict(dict_model['net'])\n",
    "    optim.load_state_dict(dict_model['optim'])\n",
    "    epoch = int(ckpt_lst[-1].split('epoch')[1].split('.pth')[0])\n",
    "\n",
    "    return net, optim, epoch\n",
    "\n",
    "##training for loop\n",
    "st_epoch = 0\n",
    "net, optimm, st_epoch = load(ckpt_dir=ckpt_dir, net=net, optim= optim)\n",
    "\n",
    "\n",
    "    #validation loop\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    loss_arr = []\n",
    "\n",
    "    for batch, data in enumerate(loader_test, 1):\n",
    "            #forward pass\n",
    "        label = data['label'].to(device)\n",
    "        input = data['input'].to(device)\n",
    "\n",
    "        output = net(input)\n",
    "\n",
    "        loss = fn_loss(output, label)\n",
    "        loss_arr += [loss.item()]\n",
    "\n",
    "        print('Test:  Batch %04d / %04d | Loss %.4f' % \n",
    "            (batch, num_batch_test, np.mean(loss_arr)))\n",
    "\n",
    "        label = fn_tonumpy(label)\n",
    "        input = fn_tonumpy(fn_denorm(input))\n",
    "        output = fn_tonumpy(fn_class(output))\n",
    "\n",
    "        for j in range(label.shape[0]):\n",
    "            id = num_batch_test * (batch -1) + j\n",
    " \n",
    "            plt.imsave(os.path.join(result_dir, 'png', 'label_%04d.png' % id), label[j].unsqueeze(), cmap ='gray')\n",
    "            plt.imsave(os.path.joint(result_dir, 'png', 'input_%04d.png'% id), input[j].unsqueeze(), cmap='gray')\n",
    "            plt.imsave(os.path.join(result_dir, 'png', 'output_%04d.png'% id), output[j].unsqueeze(), cmap='gray')\n",
    "\n",
    "            np.save(os.path.join(result_dir, 'numpy', 'label_%04d.npy'% id), label[j].squeeze())\n",
    "            np.save(os.path.join(result_dir, 'numpy', 'input_%04d.npy'% id), input[j].squeeze())\n",
    "            np.save(os.path.join(result_dir, 'numpy', 'output_%04d.npy'% id), output[j].squeeze())\n",
    "\n",
    "print('Average Test: Batch %04d / %04d | Loss %.4f' % (batch, num_batch_test, np.mean(loss_arr)))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
